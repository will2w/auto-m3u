name: IPTV Auto Builder Pro

on:
  schedule:
    - cron: "*/240 * * * *"   # æ¯ 240 åˆ†é˜è‡ªå‹•æ›´æ–°
  workflow_dispatch:           # æ‰‹å‹•è§¸ç™¼

permissions:
  contents: write             # æ˜ç¢ºè²æ˜å¯«å…¥æ¬Šé™

jobs:
  build:
    runs-on: ubuntu-latest
    timeout-minutes: 10       # è¨­ç½®è¶…æ™‚æ™‚é–“ï¼Œé¿å…ç„¡é™é‹è¡Œ

    steps:
      - name: Checkout Repository
        uses: actions/checkout@v3
        with:
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: Setup Environment
        run: |
          echo "å·¥ä½œç›®éŒ„: $(pwd)"
          echo "ç•¶å‰æ™‚é–“: $(date)"
          echo "================================="

      - name: Install Dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y curl jq parallel
          echo "å·¥å…·å®‰è£å®Œæˆ"

      - name: Download Source Lists
        run: |
          echo "é–‹å§‹ä¸‹è¼‰æ’­æ”¾åˆ—è¡¨..."
          
          # è¨­ç½®ä¸‹è¼‰è¶…æ™‚å’Œé‡è©¦
          download_with_retry() {
            local url=$1
            local output=$2
            local max_retries=3
            local retry_count=0
            
            while [ $retry_count -lt $max_retries ]; do
              if curl -L --connect-timeout 30 --max-time 120 -f -o "$output" "$url"; then
                echo "âœ“ æˆåŠŸä¸‹è¼‰: $output"
                return 0
              else
                retry_count=$((retry_count + 1))
                echo "âš  ä¸‹è¼‰å¤±æ•— ($retry_count/$max_retries): $url"
                sleep 5
              fi
            done
            
            echo "âŒ ç„¡æ³•ä¸‹è¼‰: $url"
            # å‰µå»ºç©ºæ–‡ä»¶é¿å…å¾ŒçºŒéŒ¯èª¤
            echo "#EXTM3U" > "$output"
            return 1
          }
          
          # åŒæ™‚ä¸‹è¼‰æ‰€æœ‰æ–‡ä»¶
          download_with_retry "https://freetv.fun/test_channels_china_new.m3u" "china.m3u" &
          download_with_retry "https://freetv.fun/test_channels_hong_kong_new.m3u" "hongkong.m3u" &
          download_with_retry "https://freetv.fun/test_channels_taiwan_new.m3u" "taiwan.m3u" &
          wait
          
          echo "æ’­æ”¾åˆ—è¡¨ä¸‹è¼‰å®Œæˆ"
          ls -lh *.m3u

      - name: Download EPG
        run: |
          echo "é–‹å§‹ä¸‹è¼‰ EPG..."
          if curl -L --retry 3 --connect-timeout 30 -o epg.xml "http://epg.51zmt.top:8000/e.xml"; then
            echo "âœ“ EPG ä¸‹è¼‰æˆåŠŸ"
            echo "EPG æ–‡ä»¶å¤§å°: $(wc -l epg.xml | awk '{print $1}') è¡Œ"
          else
            echo "âš  EPG ä¸‹è¼‰å¤±æ•—ï¼Œå‰µå»ºç©ºæ–‡ä»¶"
            echo "<?xml version=\"1.0\" encoding=\"UTF-8\"?><tv></tv>" > epg.xml
          fi

      - name: Build Playlist
        run: |
          echo "é–‹å§‹æ§‹å»ºæ’­æ”¾åˆ—è¡¨..."
          
          # å‰µå»ºè™•ç†è…³æœ¬
          cat > process_channels.py << 'EOF'
          #!/usr/bin/env python3
          import sys
          import re
          import subprocess
          import time
          from pathlib import Path
          
          def extract_channels(file_path):
              """å¾ M3U æ–‡ä»¶ä¸­æå–é »é“ä¿¡æ¯"""
              channels = []
              with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                  lines = f.readlines()
              
              i = 0
              while i < len(lines):
                  line = lines[i].strip()
                  if line.startswith('#EXTINF'):
                      extinf = line
                      if i + 1 < len(lines):
                          url = lines[i + 1].strip()
                          channels.append({
                              'extinf': extinf,
                              'url': url,
                              'raw': f"{extinf}\n{url}"
                          })
                          i += 2
                          continue
                  i += 1
              return channels
          
          def extract_tvg_info(extinf_line):
              """å¾ EXTINF è¡Œæå–ä¿¡æ¯"""
              info = {
                  'tvg_id': None,
                  'tvg_logo': None,
                  'group': None,
                  'name': None
              }
              
              # æå–åç¨±ï¼ˆæœ€å¾Œä¸€å€‹é€—è™Ÿå¾Œé¢çš„å…§å®¹ï¼‰
              name_match = re.search(r',([^,]+)$', extinf_line)
              if name_match:
                  info['name'] = name_match.group(1).strip()
              
              # æå– tvg-id
              tvg_id_match = re.search(r'tvg-id="([^"]+)"', extinf_line)
              if tvg_id_match:
                  info['tvg_id'] = tvg_id_match.group(1)
              
              # æå– tvg-logo
              logo_match = re.search(r'tvg-logo="([^"]+)"', extinf_line)
              if logo_match:
                  info['tvg_logo'] = logo_match.group(1)
              
              # æå– group-title
              group_match = re.search(r'group-title="([^"]+)"', extinf_line)
              if group_match:
                  info['group'] = group_match.group(1)
              
              return info
          
          def find_tvg_id_in_epg(channel_name, epg_file):
              """åœ¨ EPG æ–‡ä»¶ä¸­æŸ¥æ‰¾ tvg-id"""
              try:
                  with open(epg_file, 'r', encoding='utf-8', errors='ignore') as f:
                      content = f.read()
                      
                  # ç°¡åŒ–é »é“åç¨±ä»¥åŒ¹é…
                  simple_name = re.sub(r'[^a-zA-Z0-9]', '', channel_name).lower()
                  
                  # æŸ¥æ‰¾åŒ¹é…çš„é »é“
                  pattern = rf'channel id="([^"]+)".*?<display-name>.*?{re.escape(channel_name[:20])}.*?</display-name>'
                  matches = re.findall(pattern, content, re.IGNORECASE | re.DOTALL)
                  
                  if matches:
                      return matches[0]
                      
                  # å˜—è©¦æ›´å¯¬é¬†çš„åŒ¹é…
                  if simple_name:
                      pattern = rf'channel id="([^"]+)".*?<display-name>.*?{re.escape(simple_name)}.*?</display-name>'
                      matches = re.findall(pattern, content, re.IGNORECASE | re.DOTALL)
                      if matches:
                          return matches[0]
              except Exception as e:
                  print(f"EPG æŸ¥æ‰¾éŒ¯èª¤: {e}")
              
              return None
          
          def check_url_availability(url, timeout=3):
              """æª¢æŸ¥ URL æ˜¯å¦å¯ç”¨"""
              try:
                  result = subprocess.run(
                      ['curl', '-I', '-s', '-o', '/dev/null', '-w', '%{http_code}', '--max-time', str(timeout), url],
                      capture_output=True,
                      text=True,
                      timeout=timeout + 1
                  )
                  return result.stdout.strip() == '200'
              except:
                  return False
          
          def main():
              if len(sys.argv) < 3:
                  print("ç”¨æ³•: python script.py <area> <input_file> <output_file>")
                  sys.exit(1)
              
              area = sys.argv[1]
              input_file = sys.argv[2]
              output_file = sys.argv[3]
              epg_file = 'epg.xml' if Path('epg.xml').exists() else None
              
              print(f"è™•ç†å€åŸŸ: {area}, æ–‡ä»¶: {input_file}")
              
              # è®€å–å·²è™•ç†çš„ URL å’Œåç¨±
              processed_urls = set()
              processed_names = set()
              
              # æå–é »é“
              channels = extract_channels(input_file)
              print(f"æ‰¾åˆ° {len(channels)} å€‹é »é“")
              
              # æº–å‚™è¼¸å‡º
              output_lines = [f"\n# ===== {area} Channels ====="]
              
              valid_count = 0
              skipped_count = 0
              
              for idx, channel in enumerate(channels):
                  if idx % 50 == 0:
                      print(f"è™•ç†é€²åº¦: {idx}/{len(channels)}")
                  
                  # æå–ä¿¡æ¯
                  info = extract_tvg_info(channel['extinf'])
                  name = info['name'] or f"Channel_{idx}"
                  url = channel['url']
                  
                  # æª¢æŸ¥é‡è¤‡
                  if url in processed_urls:
                      skipped_count += 1
                      continue
                  
                  # æª¢æŸ¥åç¨±é‡è¤‡ï¼ˆç°¡åŒ–å¾Œï¼‰
                  simple_name = re.sub(r'[^a-zA-Z0-9]', '', name).lower()
                  if simple_name in processed_names:
                      skipped_count += 1
                      continue
                  
                  # æª¢æŸ¥ URL å¯ç”¨æ€§ï¼ˆå¯é¸ï¼Œæœƒé¡¯è‘—å¢åŠ è™•ç†æ™‚é–“ï¼‰
                  # if not check_url_availability(url):
                  #     skipped_count += 1
                  #     continue
                  
                  # æŸ¥æ‰¾ tvg-id
                  tvg_id = info['tvg_id']
                  if not tvg_id and epg_file and info['name']:
                      tvg_id = find_tvg_id_in_epg(info['name'], epg_file)
                  
                  # æ§‹å»ºåœ–æ¨™ URL
                  tvg_logo = info['tvg_logo']
                  if not tvg_logo and simple_name:
                      tvg_logo = f"https://raw.githubusercontent.com/fanmingming/live/main/tvicon/{simple_name}.png"
                  
                  # æ§‹å»º EXTINF è¡Œ
                  extinf_parts = ["#EXTINF:-1"]
                  if tvg_id:
                      extinf_parts.append(f'tvg-id="{tvg_id}"')
                  if tvg_logo:
                      extinf_parts.append(f'tvg-logo="{tvg_logo}"')
                  if area:
                      extinf_parts.append(f'group-title="{area}"')
                  extinf_parts.append(f',{name}')
                  
                  new_extinf = ' '.join(extinf_parts)
                  
                  # æ·»åŠ åˆ°è¼¸å‡º
                  output_lines.append(new_extinf)
                  output_lines.append(url)
                  
                  # è¨˜éŒ„å·²è™•ç†
                  processed_urls.add(url)
                  processed_names.add(simple_name)
                  valid_count += 1
              
              # å¯«å…¥è¼¸å‡ºæ–‡ä»¶
              with open(output_file, 'a', encoding='utf-8') as f:
                  f.write('\n'.join(output_lines))
              
              print(f"å€åŸŸ {area}: æ·»åŠ  {valid_count} å€‹é »é“ï¼Œè·³é {skipped_count} å€‹")
              return valid_count
          
          if __name__ == "__main__":
              main()
          EOF
          
          # å‰µå»ºè‡¨æ™‚æ–‡ä»¶
          TEMP_PLAYLIST="temp_playlist.m3u"
          
          # å¯«å…¥ M3U é ­
          echo "#EXTM3U x-tvg-url=\"https://epg.51zmt.top:8000/e.xml\"" > "$TEMP_PLAYLIST"
          echo "# Generated by IPTV Auto Builder Pro" >> "$TEMP_PLAYLIST"
          echo "# Update Time: $(date)" >> "$TEMP_PLAYLIST"
          
          # è™•ç†æ¯å€‹å€åŸŸ
          python3 process_channels.py "China" "china.m3u" "$TEMP_PLAYLIST"
          python3 process_channels.py "Hong Kong" "hongkong.m3u" "$TEMP_PLAYLIST"
          python3 process_channels.py "Taiwan" "taiwan.m3u" "$TEMP_PLAYLIST"
          
          # é‡å‘½åç‚ºæœ€çµ‚æ–‡ä»¶
          mv "$TEMP_PLAYLIST" "playlist.m3u"
          
          # çµ±è¨ˆä¿¡æ¯
          TOTAL_CHANNELS=$(grep -c "^http" playlist.m3u || echo "0")
          echo "================================="
          echo "âœ… æ’­æ”¾åˆ—è¡¨æ§‹å»ºå®Œæˆ"
          echo "ç¸½é »é“æ•¸: $TOTAL_CHANNELS"
          echo "æ–‡ä»¶å¤§å°: $(wc -l playlist.m3u | awk '{print $1}') è¡Œ"
          echo "æ–‡ä»¶å¤§å°: $(ls -lh playlist.m3u | awk '{print $5}')"
          echo "================================="
          
          # é¡¯ç¤ºå‰å¹¾å€‹é »é“ä½œç‚ºç¤ºä¾‹
          echo "å‰ 5 å€‹é »é“ç¤ºä¾‹:"
          head -20 playlist.m3u

      - name: Validate Playlist
        run: |
          echo "é©—è­‰æ’­æ”¾åˆ—è¡¨..."
          if [ ! -f "playlist.m3u" ]; then
            echo "âŒ éŒ¯èª¤: playlist.m3u æ–‡ä»¶ä¸å­˜åœ¨"
            exit 1
          fi
          
          LINE_COUNT=$(wc -l playlist.m3u | awk '{print $1}')
          if [ "$LINE_COUNT" -lt 10 ]; then
            echo "âš  è­¦å‘Š: æ’­æ”¾åˆ—è¡¨è¡Œæ•¸éå°‘ ($LINE_COUNT)"
          else
            echo "âœ“ æ’­æ”¾åˆ—è¡¨é©—è­‰é€šé ($LINE_COUNT è¡Œ)"
          fi
          
          # æª¢æŸ¥æ ¼å¼
          if grep -q "^#EXTM3U" playlist.m3u; then
            echo "âœ“ M3U æ ¼å¼æ­£ç¢º"
          else
            echo "âŒ éŒ¯èª¤: ç¼ºå°‘ #EXTM3U æ¨™é ­"
            exit 1
          fi

      - name: Commit Changes
        run: |
          echo "æäº¤æ›´æ”¹..."
          
          # é…ç½® Git
          git config --global user.email "actions@github.com"
          git config --global user.name "GitHub Actions"
          
          # æª¢æŸ¥æ˜¯å¦æœ‰æ›´æ”¹
          if git diff --quiet -- playlist.m3u 2>/dev/null; then
            echo "æ²’æœ‰æ›´æ”¹ï¼Œè·³éæäº¤"
          else
            echo "æª¢æ¸¬åˆ°æ›´æ”¹ï¼Œæäº¤ä¸­..."
            git add playlist.m3u
            git commit -m "ğŸ”„ Auto update playlist - $(date +'%Y-%m-%d %H:%M:%S')
            
            - Total channels: $(grep -c '^http' playlist.m3u)
            - Last update: $(date)"
            
            # å˜—è©¦æ¨é€
            MAX_RETRIES=3
            for i in $(seq 1 $MAX_RETRIES); do
              if git push; then
                echo "âœ“ æˆåŠŸæ¨é€åˆ°å€‰åº«"
                break
              else
                echo "âš  æ¨é€å¤±æ•— ($i/$MAX_RETRIES)ï¼Œé‡è©¦..."
                sleep 2
              fi
            done
          fi

      - name: Upload Playlist as Artifact
        uses: actions/upload-artifact@v3
        with:
          name: iptv-playlist
          path: playlist.m3u
          retention-days: 7

      - name: Final Status
        run: |
          echo "================================="
          echo "ğŸš€ IPTV Auto Builder åŸ·è¡Œå®Œæˆ"
          echo "================================="
          echo "âœ… æ’­æ”¾åˆ—è¡¨å·²æ›´æ–°"
          echo "ğŸ“Š é »é“ç¸½æ•¸: $(grep -c '^http' playlist.m3u 2>/dev/null || echo 'N/A')"
          echo "ğŸ“ æ–‡ä»¶ä½ç½®: playlist.m3u"
          echo "ğŸ•’ ä¸‹æ¬¡æ›´æ–°: 30 åˆ†é˜å¾Œ"
          echo "================================="
